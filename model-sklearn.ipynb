{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lemma_dict(path=\"data/lemma_dict.txt\"):\n",
    "    lemma_dict = dict()\n",
    "    with open(path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "        for line in lines:\n",
    "            l = line.split()\n",
    "            lemma_dict[l[0]] = l[1]\n",
    "    return lemma_dict\n",
    "\n",
    "def get_stop_words(path=\"data/stop_words_mini.txt\"):\n",
    "    stop_words = set()\n",
    "    with open(path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "        for line in lines:\n",
    "            if line[0] != '*':\n",
    "                stop_words.add(line.strip())\n",
    "    return stop_words\n",
    "\n",
    "def get_ascii(word):\n",
    "    l = \"абвгґдеєжзиіїйклмнопрстуфхцчшщьюя-\\'\"\n",
    "    s = \"!?.;\\\"'/\\\\,;()\"\n",
    "    new = \"\"\n",
    "    for w in word:\n",
    "        if w in l:\n",
    "            new += w\n",
    "        elif w in s and (new and new[-1] != ' '):\n",
    "            new += \" \"\n",
    "    return new\n",
    "\n",
    "def get_lemma_word(word, use_stop_words=True):\n",
    "    new_word = get_ascii(word.lower().strip())\n",
    "    words = [x.strip() for x in new_word.split()]\n",
    "    if len(words) <= 1:\n",
    "        if new_word and new_word in lemma_dict:\n",
    "            if not use_stop_words or new_word not in stop_words:\n",
    "                return [lemma_dict[new_word]]\n",
    "    else:\n",
    "        res = []\n",
    "        for word in words:\n",
    "            if word and word in lemma_dict:\n",
    "                if not use_stop_words or new_word not in stop_words: \n",
    "                    res.append(lemma_dict[word])\n",
    "        return res\n",
    "    return [\"\"]\n",
    "\n",
    "def get_lemma_par(par):\n",
    "    new = []\n",
    "    for sent in par.split('.'):\n",
    "        sent = get_lemma_sent(sent)\n",
    "        if sent: \n",
    "            new.append(sent)\n",
    "    return new\n",
    "\n",
    "# Main\n",
    "def get_lemma_sent(sent, use_stop_words=True):\n",
    "    new = []\n",
    "   \n",
    "    for word in sent.split():\n",
    "        word = get_lemma_word(word, use_stop_words=use_stop_words)\n",
    "        if word and word != [\"\"]: \n",
    "            for w in word:\n",
    "                new.append(w)\n",
    "    return new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_antonyms_dict(path=\"data/antonyms.txt\"):\n",
    "    out = dict()\n",
    "    with open(path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "        for line in lines:\n",
    "            row = line.split(\",\")\n",
    "            key, value = row[0], row[1]\n",
    "            key, value = key.strip(), value.strip()\n",
    "            out[key] = value\n",
    "    return out\n",
    "                \n",
    "def process_antonyms(sent):\n",
    "    out = []\n",
    "    next_skip = False\n",
    "    for i in range(len(sent) - 1):\n",
    "        if next_skip:\n",
    "            next_skip = False\n",
    "            continue\n",
    "        if sent[i] in opposite_dict:\n",
    "            if sent[i + 1] in antonyms_dict:\n",
    "                sent[i + 1] = antonyms_dict[sent[i + 1]]\n",
    "            else:\n",
    "                next_skip = True\n",
    "        else:\n",
    "            out.append(sent[i])\n",
    "    if len(sent) < 1: return None\n",
    "    if not next_skip: out.append(sent[-1])\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "opposite_dict = {'ні', 'не', 'без'}\n",
    "lemma_dict = get_lemma_dict()\n",
    "antonyms_dict = get_antonyms_dict()\n",
    "stop_words = get_stop_words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_sent(sent, use_antonyms=True, use_stop_words=True):\n",
    "    sent = get_lemma_sent(sent, use_stop_words=use_stop_words)\n",
    "    if use_antonyms:\n",
    "        sent = process_antonyms(sent)\n",
    "    if sent is None or len(sent) < 1: return None\n",
    "    return sent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['сьогодні', 'тверезий']\n"
     ]
    }
   ],
   "source": [
    "sent = \"Я була сьогодні не п'яна\"\n",
    "sent = process_sent(sent, use_antonyms=True, use_stop_words=True)\n",
    "print(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "limit = 70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import gensim\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import pandas_profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = os.path.join('data', 'ubercorpus.lowercased.lemmatized.word2vec.300d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 4s, sys: 1.16 s, total: 1min 5s\n",
      "Wall time: 1min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format(data_folder, binary=False)\n",
    "model.init_sims(replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tone</th>\n",
       "      <th>text</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>препарат его первий не не не оно же состав фор...</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1</td>\n",
       "      <td>сайт служба контроль наркотик от заперти ораль...</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1</td>\n",
       "      <td>служба контроль наркотик об том сайт один орал...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1</td>\n",
       "      <td>сайт служба контроль наркотик от заперти мл ам...</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1</td>\n",
       "      <td>розпорядження надходження інформація правоохор...</td>\n",
       "      <td>151</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tone                                               text  length\n",
       "0     0  препарат его первий не не не оно же состав фор...      69\n",
       "1    -1  сайт служба контроль наркотик от заперти ораль...      20\n",
       "2    -1  служба контроль наркотик об том сайт один орал...      14\n",
       "3    -1  сайт служба контроль наркотик от заперти мл ам...      19\n",
       "4    -1  розпорядження надходження інформація правоохор...     151"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/train.csv\")\n",
    "df[\"text\"] = df[\"text\"].astype(str)\n",
    "df[\"length\"] = df[\"text\"].apply(lambda x: len(x.split(\" \")))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(69983, 3)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df[\"length\"] < limit]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_to_vect(word):\n",
    "    try:\n",
    "        return model.wv[word]\n",
    "    except KeyError:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_to_vects(data, max_len=limit, **kwargs):\n",
    "    data = process_sent(data, **kwargs)\n",
    "    out = []\n",
    "    if not data: return\n",
    "    for word in data:\n",
    "        vect = word_to_vect(word)\n",
    "        if vect is not None:\n",
    "            out.append(vect)\n",
    "    if out is None: return\n",
    "    to_add = max_len - len(out)\n",
    "    out += [[0 for _ in range(300)] for _ in range(to_add)]\n",
    "    out = np.array(out)\n",
    "    out = out.reshape(-1)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_vects(data, max_len=limit,**kwargs):\n",
    "    \"\"\"\n",
    "    df\n",
    "    \"\"\"\n",
    "    X = []\n",
    "    y = []\n",
    "    for idx, row in df.iterrows():\n",
    "        new_row = string_to_vects(row[\"text\"], **kwargs)\n",
    "        if new_row is not None:\n",
    "            X.append(new_row)\n",
    "            y.append(row[\"tone\"])\n",
    "    if len(X) < 1: return\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_reader(regr, message):\n",
    "    vect = string_to_vects(message)\n",
    "    return regr.predict_proba([vect])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Best C = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = [0.01, 0.05, 0.1, 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.sample(frac=1)\n",
    "X, y = df_to_vects(df)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Handle memory\n",
    "del(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"solver\": [\"saga\"],\n",
    "    \"multi_class\": [\"multinomial\"],\n",
    "    \"max_iter\": [20],\n",
    "    \"C\": [0.1]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "regr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   4 out of   4 | elapsed: 13.5min remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done   4 out of   4 | elapsed: 13.5min finished\n"
     ]
    }
   ],
   "source": [
    "best_regr = GridSearchCV(regr, params, cv=4, n_jobs=8, verbose=1)\n",
    "best_regr.fit(X_train, y_train)\n",
    "best_regr.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Own check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here fit with best C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Final score:\", best_regr.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_reader(best_regr, \"Це було класно\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
